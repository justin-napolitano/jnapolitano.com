<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgresql on Justin Napolitano</title>
    <link>//localhost:1313/en/tags/postgresql/</link>
    <description>Recent content in Postgresql on Justin Napolitano</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>personal.jnapolitano@gmail.com (Justin Napolitano)</managingEditor>
    <webMaster>personal.jnapolitano@gmail.com (Justin Napolitano)</webMaster>
    <copyright>COBRACORP</copyright>
    <lastBuildDate>Fri, 09 Aug 2024 15:34:02 -0500</lastBuildDate>
    <atom:link href="//localhost:1313/en/tags/postgresql/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Airflow &#43; Neo4j DAG</title>
      <link>//localhost:1313/en/posts/airflow-docker/</link>
      <pubDate>Wed, 31 Jul 2024 14:25:13 -0500</pubDate><author>personal.jnapolitano@gmail.com (Justin Napolitano)</author>
      <guid>//localhost:1313/en/posts/airflow-docker/</guid>
      <description>Running Apache Airflow with Docker: Deploy A Neo4j Workflow Apache Airflow is a powerful tool for orchestrating complex workflows, and running it with Docker simplifies the setup and maintenance of the environment. In this guide, we will walk through setting up Apache Airflow using Docker, making sure that any changes to your DAGs (Directed Acyclic Graphs) are immediately reflected in the running environment.&#xA;Though, I really don&amp;rsquo;t think I&amp;rsquo;ll use it.</description>
    </item>
    <item>
      <title>PostGreSQL Java: Data Ingestion</title>
      <link>//localhost:1313/en/posts/sup-court-data-ingestion/</link>
      <pubDate>Wed, 31 Jul 2024 14:25:13 -0500</pubDate><author>personal.jnapolitano@gmail.com (Justin Napolitano)</author>
      <guid>//localhost:1313/en/posts/sup-court-data-ingestion/</guid>
      <description>Setting Up a Data Ingestion Workflow with Java and Google Cloud Storage Introduction In this blog post, we will walk through setting up a data ingestion workflow using Java. The workflow will download JSON data from a Google Cloud Storage (GCS) bucket, parse it, and insert it into a PostgreSQL database. We will also handle unique constraint violations gracefully.&#xA;Prerequisites Java 11 or higher installed Maven installed PostgreSQL running locally (preferably in a Docker container) Google Cloud Storage bucket with JSON files Service account key for Google Cloud Storage Setting Up the Project 1.</description>
    </item>
  </channel>
</rss>
